server:
  port: 8082

spring:
  application:
    name: llm-service

# Gemini API Configuration
gemini:
  api:
    key: ${GEMINI_API_KEY:}
    model: ${GEMINI_MODEL:gemini-2.5-flash}

management:
  endpoints:
    web:
      exposure:
        include: health,info
  endpoint:
    health:
      show-details: always

logging:
  level:
    com.mcp.llm: DEBUG
